{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Sanity Check for Question 1d: Encode\r\n",
      "--------------------------------------------------------------------------------\r\n",
      "enc_hiddens Sanity Checks Passed!\r\n",
      "dec_init_state[0] Sanity Checks Passed!\r\n",
      "dec_init_state[1] Sanity Checks Passed!\r\n",
      "--------------------------------------------------------------------------------\r\n",
      "All Sanity Checks Passed for Question 1d: Encode!\r\n",
      "--------------------------------------------------------------------------------\r\n"
     ]
    }
   ],
   "source": [
    "!python sanity_check.py 1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Running Sanity Check for Question 1e: Decode\n",
      "--------------------------------------------------------------------------------\n",
      "combined_outputs Sanity Checks Passed!\n",
      "--------------------------------------------------------------------------------\n",
      "All Sanity Checks Passed for Question 1e: Decode!\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "!python sanity_check.py 1e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\r\n",
      "Running Sanity Check for Question 1f: Step\r\n",
      "--------------------------------------------------------------------------------\r\n",
      "a_t.shape =  torch.Size([5, 6])\r\n",
      "dec_state[0].shape =  torch.Size([5, 3])\r\n",
      "dec_state[0] Sanity Checks Passed!\r\n",
      "dec_state[1] Sanity Checks Passed!\r\n",
      "combined_output  Sanity Checks Passed!\r\n",
      "e_t Sanity Checks Passed!\r\n",
      "--------------------------------------------------------------------------------\r\n",
      "All Sanity Checks Passed for Question 1f: Step!\r\n",
      "--------------------------------------------------------------------------------\r\n"
     ]
    }
   ],
   "source": [
    "!python sanity_check.py 1f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read in source sentences: ./en_es_data/train.es\n",
      "read in target sentences: ./en_es_data/train.en\n",
      "initialize source vocabulary ..\n",
      "number of word types: 172418, number of word types w/ frequency >= 2: 80623\n",
      "initialize target vocabulary ..\n",
      "number of word types: 128873, number of word types w/ frequency >= 2: 64215\n",
      "generated vocabulary, source 50004 words, target 50002 words\n",
      "vocabulary saved to vocab.json\n"
     ]
    }
   ],
   "source": [
    "!sh run.sh vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uniformly initialize parameters [-0.100000, +0.100000]\n",
      "use device: cpu\n",
      "begin Maximum Likelihood training\n",
      "epoch 1, iter 10, avg. loss 167.30, avg. ppl 23634.30 cum. examples 320, speed 45.16 words/sec, time elapsed 117.71 sec\n",
      "epoch 1, iter 20, avg. loss 142.21, avg. ppl 3156.01 cum. examples 640, speed 48.83 words/sec, time elapsed 233.39 sec\n",
      "epoch 1, iter 30, avg. loss 137.87, avg. ppl 1774.73 cum. examples 960, speed 48.34 words/sec, time elapsed 355.37 sec\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!sh run.sh train_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5MB 4.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /jet/lib/python3.6/site-packages (from nltk) (1.11.0)\n",
      "Building wheels for collected packages: nltk\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nltk: filename=nltk-3.4.5-cp36-none-any.whl size=1450725 sha256=e42713d7493d9adf4aac85de074e6f20f4cc85f30835a7ed2e9fcd57179be48e\n",
      "  Stored in directory: /jet/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
      "Successfully built nltk\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.4.5\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting docopt\n",
      "  Downloading https://files.pythonhosted.org/packages/a2/55/8f8cab2afd404cf578136ef2cc5dfb50baa1761b68c9da1fb1e4eed343c9/docopt-0.6.2.tar.gz\n",
      "Building wheels for collected packages: docopt\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=19858 sha256=3b2a39d6f5e95489d52b2c4b72b8e2756507e335e2430c7adc2f575cad9ca655\n",
      "  Stored in directory: /jet/.cache/pip/wheels/9b/04/dd/7daf4150b6d9b12949298737de9431a324d4b797ffd63f526e\n",
      "Successfully built docopt\n",
      "Installing collected packages: docopt\n",
      "Successfully installed docopt-0.6.2\n"
     ]
    }
   ],
   "source": [
    "!pip install docopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\r\n",
      "\r\n",
      "if [ \"$1\" = \"train\" ]; then\r\n",
      "\tCUDA_VISIBLE_DEVICES=0 python run.py train --train-src=./en_es_data/train.es --train-tgt=./en_es_data/train.en --dev-src=./en_es_data/dev.es --dev-tgt=./en_es_data/dev.en --vocab=vocab.json --cuda\r\n",
      "elif [ \"$1\" = \"test\" ]; then\r\n",
      "        CUDA_VISIBLE_DEVICES=0 python run.py decode model.bin ./en_es_data/test.es ./en_es_data/test.en outputs/test_outputs.txt --cuda\r\n",
      "elif [ \"$1\" = \"train_local\" ]; then\r\n",
      "\tpython run.py train --train-src=./en_es_data/train.es --train-tgt=./en_es_data/train.en --dev-src=./en_es_data/dev.es --dev-tgt=./en_es_data/dev.en --vocab=vocab.json\r\n",
      "elif [ \"$1\" = \"test_local\" ]; then\r\n",
      "    python run.py decode model.bin ./en_es_data/test.es ./en_es_data/test.en outputs/test_outputs.txt\r\n",
      "elif [ \"$1\" = \"vocab\" ]; then\r\n",
      "\tpython vocab.py --train-src=./en_es_data/train.es --train-tgt=./en_es_data/train.en vocab.json\r\n",
      "else\r\n",
      "\techo \"Invalid Option Selected\"\r\n",
      "fi\r\n"
     ]
    }
   ],
   "source": [
    "!cat run.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "dev_data_src = read_corpus('./en_es_data/train.en', source='src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216617"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_data_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', '', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', '', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', '', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', '', 'has', 'shrunk', 'by', '40', 'percent.'], ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', '', 'because', 'it', \"doesn't\", 'show', 'the', 'thickness', 'of', 'the', 'ice.'], ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', '', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.'], ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.'], ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', '', 'a', 'rapid', 'fast-forward', 'of', \"what's\", 'happened', 'over', 'the', 'last', '25', 'years.'], ['The', 'permanent', 'ice', 'is', 'marked', 'in', 'red.'], ['As', 'you', 'see,', 'it', 'expands', 'to', 'the', 'dark', 'blue', '--', '', \"that's\", 'the', 'annual', 'ice', 'in', 'winter,', '', 'and', 'it', 'contracts', 'in', 'summer.'], ['The', 'so-called', 'permanent', 'ice,', 'five', 'years', 'old', 'or', 'older,', '', 'you', 'can', 'see', 'is', 'almost', 'like', 'blood,', '', 'spilling', 'out', 'of', 'the', 'body', 'here.'], ['In', '25', 'years', \"it's\", 'gone', 'from', 'this,', 'to', 'this.'], ['This', 'is', 'a', 'problem', 'because', 'the', 'warming', '', 'heats', 'up', 'the', 'frozen', 'ground', 'around', 'the', 'Arctic', 'Ocean,', '', 'where', 'there', 'is', 'a', 'massive', 'amount', 'of', 'frozen', 'carbon', '', 'which,', 'when', 'it', 'thaws,', 'is', 'turned', 'into', 'methane', 'by', 'microbes.']]\n"
     ]
    }
   ],
   "source": [
    "print(dev_data_src[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dev_data_src = read_corpus('../../Data/test', source='src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_data_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['근본적인', '문제는', '제도', '개선을', '통해', '이뤄내야', '하지만', '당면한', '아시안게임', '금메달을', '위해선', '김현수의', '리더십이', '필요하', '시점이다.'], ['근본적인', '해결책은', '아니라는', '지적이', '있지만', '대내외', '여건이', '좋지', '않고', '정부가', '쓸', '카드도', '많지', '않다는', '점에서', '재정', '확대는', '불가피한', '측면이', '있다.'], ['근사하게', '‘혼밥’을', '즐기고', '건강도', '챙기려는', '1인', '가구도', '늘면서,', '간편히', '양식과', '샐러드를', '만들', '수', '있는', '주방도구의', '판매량도', '급증세다.'], ['근사한', '오디오', '세트도', '없는', '그가', '이', '음악을', '듣는', '방법은', '컴퓨터를', '켜고', '유튜브에서', '검색', '단어를', '쳐', '넣으면', '된다.'], ['근육량을', '증가시키기', '위해', '매일', '양질의', '단백질', '식품을', '적절히', '섭취하는', '것이', '중요한데,', '조', '원장은', '‘밀크어트(우유를', '마시면서', '하는', '다이어트)’를', '예를', '들며', '우유의', '효능을', '소개할', '예정이다.'], ['근육의', '감소는', '운동능력', '저하로', '골절', '위험을', '증가시킬', '뿐만', '아니라', '일상생활의', '수행능력이', '저하돼', '그로', '인한', '사망', '위험까지', '증가할', '수', '있다.'], ['근육이', '줄어드는', '것을', '그대로', '방치하면', '30년만', '지나도', '몸을', '지탱할', '수', '없을', '정도의', '약한', '체력이', '되고', '만다.'], ['근처를', '지나던', '마을', '주민에', '의해', '구조된', '아이는', '다행히', '목숨을', '건져', '현재는', '안정을', '찾은', '것으로', '알려졌다.'], ['글', '말미에도', '“시민이', '다른', '시민의', '외침에', '귀', '기울일', '때,', '그리고', '그의', '아픔에', '공감하고', '연대할', '때', '비로소', '공화(共和)”라고', '강조했다.'], ['글', '작성자는', '“시험보는', '도중에', '시끄러운', '음악이', '계속', '나오는데도', '감독관이나', '학교', '관계자들이', '제지하지', '않았다”며', '분통을', '터뜨렸습니다.']]\n"
     ]
    }
   ],
   "source": [
    "print(dev_data_src[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:local_nmt]",
   "language": "python",
   "name": "conda-env-local_nmt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
