{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/Project3\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil -m cp nmt_bi_plus_char_0811.tar.gz gs://root-territory-252903/NMT_2020_august/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nmt_bi_mono_mapping_combined_0717/\n",
      "nmt_bi_mono_mapping_combined_0717/model_embeddings_orig.py\n",
      "nmt_bi_mono_mapping_combined_0717/sanity_check.py\n",
      "nmt_bi_mono_mapping_combined_0717/local_env.yml\n",
      "nmt_bi_mono_mapping_combined_0717/data_preprocessing.ipynb\n",
      "nmt_bi_mono_mapping_combined_0717/outputs/\n",
      "nmt_bi_mono_mapping_combined_0717/outputs/bcktr_en2ko.txt\n",
      "nmt_bi_mono_mapping_combined_0717/outputs/test_en2ko.txt\n",
      "nmt_bi_mono_mapping_combined_0717/outputs/test_ko2en.txt\n",
      "nmt_bi_mono_mapping_combined_0717/outputs/.ipynb_checkpoints/\n",
      "nmt_bi_mono_mapping_combined_0717/outputs/.ipynb_checkpoints/test_outputs_33_2-checkpoint.txt\n",
      "nmt_bi_mono_mapping_combined_0717/outputs/.ipynb_checkpoints/test_en2ko-checkpoint.txt\n",
      "nmt_bi_mono_mapping_combined_0717/outputs/.ipynb_checkpoints/test_en2en-checkpoint.txt\n",
      "nmt_bi_mono_mapping_combined_0717/outputs/.ipynb_checkpoints/test_outputs_0519_02-checkpoint.txt\n",
      "nmt_bi_mono_mapping_combined_0717/outputs/.ipynb_checkpoints/test_outputs_32_3-checkpoint.txt\n",
      "nmt_bi_mono_mapping_combined_0717/outputs/.ipynb_checkpoints/test_outputs_fromwhere-checkpoint.txt\n",
      "nmt_bi_mono_mapping_combined_0717/outputs/.ipynb_checkpoints/test_outputs_30-checkpoint.txt\n",
      "nmt_bi_mono_mapping_combined_0717/outputs/.ipynb_checkpoints/test_outputs_31-checkpoint.txt\n",
      "nmt_bi_mono_mapping_combined_0717/outputs/.ipynb_checkpoints/test_outputs_32.3-checkpoint.txt\n",
      "nmt_bi_mono_mapping_combined_0717/outputs/.ipynb_checkpoints/test_outputs_31_3-checkpoint.txt\n",
      "nmt_bi_mono_mapping_combined_0717/outputs/.ipynb_checkpoints/test_ko2en-checkpoint.txt\n",
      "nmt_bi_mono_mapping_combined_0717/outputs/.ipynb_checkpoints/test_outputs_32_2-checkpoint.txt\n",
      "nmt_bi_mono_mapping_combined_0717/outputs/.ipynb_checkpoints/test_outputs-checkpoint.txt\n",
      "nmt_bi_mono_mapping_combined_0717/outputs/bcktr_en2ko.txt_mapping\n",
      "nmt_bi_mono_mapping_combined_0717/update_mapping.py\n",
      "nmt_bi_mono_mapping_combined_0717/nmt_model_orig.py\n",
      "nmt_bi_mono_mapping_combined_0717/__pycache__/\n",
      "nmt_bi_mono_mapping_combined_0717/__pycache__/model_embeddings.cpython-35.pyc\n",
      "nmt_bi_mono_mapping_combined_0717/__pycache__/update_mapping.cpython-37.pyc\n",
      "nmt_bi_mono_mapping_combined_0717/__pycache__/net_model.cpython-36.pyc\n",
      "nmt_bi_mono_mapping_combined_0717/__pycache__/utils.cpython-36.pyc\n",
      "nmt_bi_mono_mapping_combined_0717/__pycache__/utils.cpython-35.pyc\n",
      "nmt_bi_mono_mapping_combined_0717/__pycache__/vocab.cpython-35.pyc\n",
      "nmt_bi_mono_mapping_combined_0717/__pycache__/char_embeddings.cpython-37.pyc\n",
      "nmt_bi_mono_mapping_combined_0717/__pycache__/net_util.cpython-36.pyc\n",
      "nmt_bi_mono_mapping_combined_0717/__pycache__/nmt_model.cpython-37.pyc\n",
      "nmt_bi_mono_mapping_combined_0717/__pycache__/vocab.cpython-36.pyc\n",
      "nmt_bi_mono_mapping_combined_0717/__pycache__/model_embeddings.cpython-36.pyc\n",
      "nmt_bi_mono_mapping_combined_0717/__pycache__/vocab.cpython-37.pyc\n",
      "nmt_bi_mono_mapping_combined_0717/__pycache__/utils.cpython-37.pyc\n",
      "nmt_bi_mono_mapping_combined_0717/__pycache__/model_embeddings.cpython-37.pyc\n",
      "nmt_bi_mono_mapping_combined_0717/__pycache__/nmt_model.cpython-35.pyc\n",
      "nmt_bi_mono_mapping_combined_0717/__pycache__/nmt_model.cpython-36.pyc\n",
      "nmt_bi_mono_mapping_combined_0717/__pycache__/update_mapping.cpython-36.pyc\n",
      "nmt_bi_mono_mapping_combined_0717/gpu_requirements.txt\n",
      "nmt_bi_mono_mapping_combined_0717/en_es_data/\n",
      "nmt_bi_mono_mapping_combined_0717/en_es_data/train4.ko\n",
      "nmt_bi_mono_mapping_combined_0717/en_es_data/dev.ko\n",
      "nmt_bi_mono_mapping_combined_0717/en_es_data/dev.en\n",
      "nmt_bi_mono_mapping_combined_0717/en_es_data/train_mono.en\n",
      "nmt_bi_mono_mapping_combined_0717/en_es_data/train_test.en\n",
      "nmt_bi_mono_mapping_combined_0717/en_es_data/train1.en\n",
      "nmt_bi_mono_mapping_combined_0717/en_es_data/train.ko\n",
      "nmt_bi_mono_mapping_combined_0717/en_es_data/train/\n",
      "nmt_bi_mono_mapping_combined_0717/en_es_data/train/train_vocab.ko\n",
      "nmt_bi_mono_mapping_combined_0717/en_es_data/train/.ipynb_checkpoints/\n",
      "nmt_bi_mono_mapping_combined_0717/en_es_data/train/train_vocab.en\n",
      "nmt_bi_mono_mapping_combined_0717/en_es_data/train1.ko\n",
      "nmt_bi_mono_mapping_combined_0717/en_es_data/train_mono.ko\n",
      "nmt_bi_mono_mapping_combined_0717/en_es_data/temp/\n",
      "nmt_bi_mono_mapping_combined_0717/en_es_data/temp/dev.ko\n",
      "nmt_bi_mono_mapping_combined_0717/en_es_data/temp/dev.en\n",
      "nmt_bi_mono_mapping_combined_0717/en_es_data/temp/test.ko\n",
      "nmt_bi_mono_mapping_combined_0717/en_es_data/temp/test.en\n",
      "nmt_bi_mono_mapping_combined_0717/en_es_data/back.en\n",
      "nmt_bi_mono_mapping_combined_0717/en_es_data/train4_before.en\n",
      "nmt_bi_mono_mapping_combined_0717/en_es_data/train_test.ko\n",
      "nmt_bi_mono_mapping_combined_0717/en_es_data/train3.en\n",
      "nmt_bi_mono_mapping_combined_0717/en_es_data/w_train.en\n",
      "nmt_bi_mono_mapping_combined_0717/en_es_data/train.en\n",
      "nmt_bi_mono_mapping_combined_0717/en_es_data/train_mono_org.ko\n"
     ]
    }
   ],
   "source": [
    "!tar -czvf nmt_bi_plus_char_0811.tar.gz nmt_bi_mono_mapping_combined_0717"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uniformly initialize parameters [-0.100000, +0.100000]\n",
      "use device: cuda:0\n",
      "begin Maximum Likelihood training\n",
      "slang : en, tlang : ko\n",
      "/home/jupyter/Project3/nmt_bi_mono_mapping_combined_0717/nmt_model.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  XO = torch.tensor(pad_sequence(XO)).to(self.device) #,device = self.device) #<=[:-1]\n",
      "epoch 1, iter 20, avg. loss 347.40, avg. ppl 543.75 cum. examples 160, speed 659.21 words/sec, time elapsed 13.39 sec\n",
      "epoch 1, iter 40, avg. loss 282.61, avg. ppl 271.69 cum. examples 320, speed 616.53 words/sec, time elapsed 26.47 sec\n",
      "epoch 1, iter 60, avg. loss 285.18, avg. ppl 240.24 cum. examples 480, speed 627.89 words/sec, time elapsed 39.73 sec\n",
      "epoch 1, iter 80, avg. loss 270.92, avg. ppl 141.91 cum. examples 640, speed 655.01 words/sec, time elapsed 53.09 sec\n",
      "epoch 1, iter 100, avg. loss 279.53, avg. ppl 106.13 cum. examples 800, speed 692.39 words/sec, time elapsed 66.93 sec\n",
      "epoch 1, iter 120, avg. loss 261.34, avg. ppl 128.13 cum. examples 960, speed 657.49 words/sec, time elapsed 80.04 sec\n",
      "epoch 1, iter 140, avg. loss 256.23, avg. ppl 100.34 cum. examples 1120, speed 663.32 words/sec, time elapsed 93.45 sec\n",
      "epoch 1, iter 160, avg. loss 242.81, avg. ppl 102.40 cum. examples 1280, speed 664.60 words/sec, time elapsed 106.08 sec\n",
      "epoch 1, iter 180, avg. loss 256.85, avg. ppl 114.24 cum. examples 1440, speed 657.17 words/sec, time elapsed 119.28 sec\n",
      "epoch 1, iter 200, avg. loss 254.07, avg. ppl 89.74 cum. examples 1600, speed 687.56 words/sec, time elapsed 132.42 sec\n",
      "epoch 1, iter 220, avg. loss 235.18, avg. ppl 105.45 cum. examples 1760, speed 624.41 words/sec, time elapsed 145.36 sec\n",
      "epoch 1, iter 240, avg. loss 237.67, avg. ppl 75.44 cum. examples 1920, speed 675.00 words/sec, time elapsed 158.39 sec\n",
      "epoch 1, iter 260, avg. loss 233.15, avg. ppl 80.12 cum. examples 2080, speed 648.52 words/sec, time elapsed 171.51 sec\n",
      "epoch 1, iter 280, avg. loss 239.13, avg. ppl 78.12 cum. examples 2240, speed 642.65 words/sec, time elapsed 185.18 sec\n",
      "epoch 1, iter 300, avg. loss 236.45, avg. ppl 75.53 cum. examples 2400, speed 650.89 words/sec, time elapsed 198.62 sec\n",
      "epoch 1, iter 320, avg. loss 237.67, avg. ppl 83.42 cum. examples 2560, speed 647.89 words/sec, time elapsed 211.88 sec\n",
      "epoch 1, iter 340, avg. loss 250.69, avg. ppl 69.37 cum. examples 2720, speed 665.06 words/sec, time elapsed 226.11 sec\n",
      "epoch 1, iter 360, avg. loss 238.97, avg. ppl 60.65 cum. examples 2880, speed 679.35 words/sec, time elapsed 239.82 sec\n",
      "epoch 1, iter 380, avg. loss 233.86, avg. ppl 65.63 cum. examples 3040, speed 656.85 words/sec, time elapsed 253.43 sec\n",
      "epoch 1, iter 400, avg. loss 218.93, avg. ppl 69.28 cum. examples 3200, speed 639.83 words/sec, time elapsed 266.35 sec\n",
      "epoch 1, iter 400, cum. loss 254.93, cum. ppl 106.77 cum. examples 3200\n",
      "begin validation ...\n",
      "validation: iter 400, dev. ppl 81.786423\n",
      "save currently the best model to [model.bin]\n",
      "save model parameters to [model.bin]\n",
      "epoch 1, iter 420, avg. loss 223.63, avg. ppl 65.66 cum. examples 160, speed 278.88 words/sec, time elapsed 297.01 sec\n",
      "epoch 1, iter 440, avg. loss 223.34, avg. ppl 60.73 cum. examples 320, speed 660.89 words/sec, time elapsed 310.18 sec\n",
      "epoch 1, iter 460, avg. loss 221.96, avg. ppl 68.36 cum. examples 480, speed 646.80 words/sec, time elapsed 323.18 sec\n",
      "epoch 1, iter 480, avg. loss 222.39, avg. ppl 66.19 cum. examples 640, speed 648.36 words/sec, time elapsed 336.27 sec\n",
      "epoch 1, iter 500, avg. loss 226.08, avg. ppl 72.33 cum. examples 800, speed 631.74 words/sec, time elapsed 349.64 sec\n",
      "epoch 1, iter 520, avg. loss 217.91, avg. ppl 63.26 cum. examples 960, speed 652.02 words/sec, time elapsed 362.54 sec\n",
      "epoch 1, iter 540, avg. loss 210.92, avg. ppl 45.36 cum. examples 1120, speed 685.28 words/sec, time elapsed 375.45 sec\n",
      "epoch 1, iter 560, avg. loss 222.33, avg. ppl 55.96 cum. examples 1280, speed 660.65 words/sec, time elapsed 388.82 sec\n",
      "epoch 1, iter 580, avg. loss 219.21, avg. ppl 56.73 cum. examples 1440, speed 684.44 words/sec, time elapsed 401.51 sec\n",
      "epoch 1, iter 600, avg. loss 224.10, avg. ppl 63.23 cum. examples 1600, speed 649.33 words/sec, time elapsed 414.83 sec\n",
      "epoch 1, iter 620, avg. loss 222.94, avg. ppl 57.68 cum. examples 1760, speed 667.00 words/sec, time elapsed 428.02 sec\n",
      "epoch 1, iter 640, avg. loss 215.75, avg. ppl 52.89 cum. examples 1920, speed 664.55 words/sec, time elapsed 441.11 sec\n",
      "epoch 1, iter 660, avg. loss 211.81, avg. ppl 52.46 cum. examples 2080, speed 665.38 words/sec, time elapsed 453.97 sec\n",
      "epoch 1, iter 680, avg. loss 218.91, avg. ppl 62.68 cum. examples 2240, speed 649.30 words/sec, time elapsed 467.01 sec\n",
      "epoch 1, iter 700, avg. loss 218.38, avg. ppl 53.26 cum. examples 2400, speed 668.62 words/sec, time elapsed 480.15 sec\n",
      "epoch 1, iter 720, avg. loss 217.02, avg. ppl 60.03 cum. examples 2560, speed 646.78 words/sec, time elapsed 493.26 sec\n",
      "epoch 1, iter 740, avg. loss 213.04, avg. ppl 48.23 cum. examples 2720, speed 672.85 words/sec, time elapsed 506.33 sec\n",
      "epoch 1, iter 760, avg. loss 209.07, avg. ppl 47.49 cum. examples 2880, speed 671.96 words/sec, time elapsed 519.23 sec\n",
      "epoch 1, iter 780, avg. loss 211.09, avg. ppl 53.07 cum. examples 3040, speed 635.25 words/sec, time elapsed 532.62 sec\n",
      "epoch 1, iter 800, avg. loss 223.50, avg. ppl 47.82 cum. examples 3200, speed 686.30 words/sec, time elapsed 546.09 sec\n",
      "epoch 1, iter 800, cum. loss 218.67, cum. ppl 57.07 cum. examples 3200\n",
      "begin validation ...\n",
      "validation: iter 800, dev. ppl 62.727692\n",
      "save currently the best model to [model.bin]\n",
      "save model parameters to [model.bin]\n",
      "epoch 1, iter 820, avg. loss 218.70, avg. ppl 51.81 cum. examples 160, speed 309.75 words/sec, time elapsed 574.71 sec\n",
      "epoch 1, iter 840, avg. loss 218.08, avg. ppl 53.95 cum. examples 320, speed 672.87 words/sec, time elapsed 587.71 sec\n",
      "epoch 1, iter 860, avg. loss 201.10, avg. ppl 45.48 cum. examples 480, speed 655.70 words/sec, time elapsed 600.56 sec\n",
      "epoch 1, iter 880, avg. loss 209.88, avg. ppl 46.14 cum. examples 640, speed 660.49 words/sec, time elapsed 613.83 sec\n",
      "epoch 1, iter 900, avg. loss 212.81, avg. ppl 48.89 cum. examples 800, speed 656.70 words/sec, time elapsed 627.16 sec\n",
      "epoch 1, iter 920, avg. loss 209.11, avg. ppl 38.93 cum. examples 960, speed 702.15 words/sec, time elapsed 640.18 sec\n",
      "epoch 1, iter 940, avg. loss 221.02, avg. ppl 52.44 cum. examples 1120, speed 660.62 words/sec, time elapsed 653.69 sec\n",
      "epoch 1, iter 960, avg. loss 199.52, avg. ppl 46.92 cum. examples 1280, speed 661.06 words/sec, time elapsed 666.24 sec\n",
      "epoch 1, iter 980, avg. loss 207.40, avg. ppl 42.27 cum. examples 1440, speed 676.61 words/sec, time elapsed 679.34 sec\n",
      "epoch 1, iter 1000, avg. loss 200.99, avg. ppl 42.25 cum. examples 1600, speed 664.49 words/sec, time elapsed 692.27 sec\n",
      "epoch 1, iter 1020, avg. loss 214.85, avg. ppl 53.82 cum. examples 1760, speed 639.68 words/sec, time elapsed 705.75 sec\n",
      "epoch 1, iter 1040, avg. loss 209.88, avg. ppl 52.88 cum. examples 1920, speed 654.65 words/sec, time elapsed 718.68 sec\n",
      "epoch 1, iter 1060, avg. loss 201.99, avg. ppl 42.71 cum. examples 2080, speed 655.69 words/sec, time elapsed 731.81 sec\n",
      "epoch 1, iter 1080, avg. loss 207.22, avg. ppl 43.85 cum. examples 2240, speed 683.11 words/sec, time elapsed 744.65 sec\n",
      "epoch 1, iter 1100, avg. loss 199.86, avg. ppl 42.90 cum. examples 2400, speed 660.10 words/sec, time elapsed 757.53 sec\n",
      "epoch 1, iter 1120, avg. loss 198.75, avg. ppl 40.72 cum. examples 2560, speed 672.21 words/sec, time elapsed 770.30 sec\n",
      "epoch 1, iter 1140, avg. loss 209.34, avg. ppl 38.87 cum. examples 2720, speed 668.45 words/sec, time elapsed 783.99 sec\n",
      "epoch 1, iter 1160, avg. loss 209.45, avg. ppl 44.28 cum. examples 2880, speed 652.14 words/sec, time elapsed 797.54 sec\n",
      "epoch 1, iter 1180, avg. loss 207.43, avg. ppl 43.72 cum. examples 3040, speed 657.75 words/sec, time elapsed 810.90 sec\n",
      "epoch 1, iter 1200, avg. loss 199.20, avg. ppl 41.69 cum. examples 3200, speed 655.04 words/sec, time elapsed 823.94 sec\n",
      "epoch 1, iter 1200, cum. loss 207.83, cum. ppl 45.45 cum. examples 3200\n",
      "begin validation ...\n",
      "validation: iter 1200, dev. ppl 52.862070\n",
      "save currently the best model to [model.bin]\n",
      "save model parameters to [model.bin]\n",
      "epoch 1, iter 1220, avg. loss 198.44, avg. ppl 42.48 cum. examples 160, speed 290.61 words/sec, time elapsed 853.08 sec\n",
      "epoch 1, iter 1240, avg. loss 196.82, avg. ppl 40.43 cum. examples 320, speed 642.68 words/sec, time elapsed 866.33 sec\n",
      "epoch 1, iter 1260, avg. loss 204.57, avg. ppl 41.30 cum. examples 480, speed 680.26 words/sec, time elapsed 879.26 sec\n",
      "epoch 1, iter 1280, avg. loss 202.21, avg. ppl 38.45 cum. examples 640, speed 658.86 words/sec, time elapsed 892.72 sec\n",
      "epoch 1, iter 1300, avg. loss 208.41, avg. ppl 44.26 cum. examples 800, speed 661.65 words/sec, time elapsed 906.01 sec\n",
      "epoch 1, iter 1320, avg. loss 204.88, avg. ppl 46.79 cum. examples 960, speed 631.80 words/sec, time elapsed 919.51 sec\n",
      "epoch 1, iter 1340, avg. loss 202.64, avg. ppl 39.94 cum. examples 1120, speed 653.52 words/sec, time elapsed 932.96 sec\n",
      "epoch 1, iter 1360, avg. loss 197.40, avg. ppl 38.74 cum. examples 1280, speed 648.35 words/sec, time elapsed 946.28 sec\n",
      "epoch 1, iter 1380, avg. loss 199.22, avg. ppl 41.60 cum. examples 1440, speed 632.87 words/sec, time elapsed 959.79 sec\n",
      "epoch 1, iter 1400, avg. loss 195.26, avg. ppl 37.80 cum. examples 1600, speed 670.39 words/sec, time elapsed 972.62 sec\n",
      "epoch 1, iter 1420, avg. loss 197.67, avg. ppl 43.40 cum. examples 1760, speed 651.05 words/sec, time elapsed 985.51 sec\n",
      "epoch 1, iter 1440, avg. loss 200.34, avg. ppl 36.66 cum. examples 1920, speed 676.04 words/sec, time elapsed 998.67 sec\n",
      "epoch 1, iter 1460, avg. loss 206.16, avg. ppl 37.64 cum. examples 2080, speed 680.81 words/sec, time elapsed 1012.03 sec\n",
      "epoch 1, iter 1480, avg. loss 201.99, avg. ppl 41.17 cum. examples 2240, speed 647.39 words/sec, time elapsed 1025.45 sec\n",
      "epoch 1, iter 1500, avg. loss 192.01, avg. ppl 42.53 cum. examples 2400, speed 636.37 words/sec, time elapsed 1038.33 sec\n",
      "epoch 1, iter 1520, avg. loss 202.64, avg. ppl 44.57 cum. examples 2560, speed 651.04 words/sec, time elapsed 1051.44 sec\n",
      "epoch 1, iter 1540, avg. loss 197.67, avg. ppl 37.33 cum. examples 2720, speed 664.95 words/sec, time elapsed 1064.58 sec\n",
      "epoch 1, iter 1560, avg. loss 206.56, avg. ppl 40.58 cum. examples 2880, speed 651.75 words/sec, time elapsed 1078.27 sec\n",
      "epoch 1, iter 1580, avg. loss 201.94, avg. ppl 43.56 cum. examples 3040, speed 639.41 words/sec, time elapsed 1091.66 sec\n",
      "epoch 1, iter 1600, avg. loss 197.87, avg. ppl 36.32 cum. examples 3200, speed 673.66 words/sec, time elapsed 1104.75 sec\n",
      "epoch 1, iter 1600, cum. loss 200.74, cum. ppl 40.64 cum. examples 3200\n",
      "begin validation ...\n",
      "validation: iter 1600, dev. ppl 45.827324\n",
      "save currently the best model to [model.bin]\n",
      "save model parameters to [model.bin]\n",
      "epoch 1, iter 1620, avg. loss 197.55, avg. ppl 39.45 cum. examples 160, speed 288.75 words/sec, time elapsed 1134.53 sec\n",
      "epoch 1, iter 1640, avg. loss 201.52, avg. ppl 39.89 cum. examples 320, speed 652.58 words/sec, time elapsed 1147.94 sec\n",
      "epoch 1, iter 1660, avg. loss 191.66, avg. ppl 33.57 cum. examples 480, speed 672.92 words/sec, time elapsed 1160.91 sec\n",
      "epoch 1, iter 1680, avg. loss 201.36, avg. ppl 36.15 cum. examples 640, speed 673.53 words/sec, time elapsed 1174.24 sec\n",
      "epoch 1, iter 1700, avg. loss 197.20, avg. ppl 32.20 cum. examples 800, speed 664.55 words/sec, time elapsed 1187.92 sec\n",
      "epoch 1, iter 1720, avg. loss 203.55, avg. ppl 41.44 cum. examples 960, speed 654.53 words/sec, time elapsed 1201.28 sec\n",
      "epoch 1, iter 1740, avg. loss 192.64, avg. ppl 32.60 cum. examples 1120, speed 678.55 words/sec, time elapsed 1214.31 sec\n",
      "epoch 1, iter 1760, avg. loss 197.10, avg. ppl 35.11 cum. examples 1280, speed 678.58 words/sec, time elapsed 1227.37 sec\n",
      "epoch 1, iter 1780, avg. loss 195.24, avg. ppl 40.93 cum. examples 1440, speed 622.93 words/sec, time elapsed 1240.88 sec\n",
      "epoch 1, iter 1800, avg. loss 190.64, avg. ppl 31.28 cum. examples 1600, speed 693.99 words/sec, time elapsed 1253.65 sec\n",
      "epoch 1, iter 1820, avg. loss 190.61, avg. ppl 37.51 cum. examples 1760, speed 665.19 words/sec, time elapsed 1266.30 sec\n",
      "epoch 1, iter 1840, avg. loss 192.49, avg. ppl 33.04 cum. examples 1920, speed 689.02 words/sec, time elapsed 1279.08 sec\n",
      "epoch 1, iter 1860, avg. loss 191.35, avg. ppl 33.45 cum. examples 2080, speed 648.37 words/sec, time elapsed 1292.53 sec\n",
      "epoch 1, iter 1880, avg. loss 201.77, avg. ppl 35.03 cum. examples 2240, speed 673.20 words/sec, time elapsed 1306.01 sec\n",
      "epoch 1, iter 1900, avg. loss 193.17, avg. ppl 36.16 cum. examples 2400, speed 667.66 words/sec, time elapsed 1318.92 sec\n",
      "epoch 1, iter 1920, avg. loss 195.33, avg. ppl 42.27 cum. examples 2560, speed 644.91 words/sec, time elapsed 1331.86 sec\n",
      "epoch 1, iter 1940, avg. loss 195.77, avg. ppl 34.33 cum. examples 2720, speed 663.82 words/sec, time elapsed 1345.20 sec\n",
      "epoch 1, iter 1960, avg. loss 198.10, avg. ppl 34.25 cum. examples 2880, speed 669.31 words/sec, time elapsed 1358.60 sec\n",
      "epoch 1, iter 1980, avg. loss 186.52, avg. ppl 33.73 cum. examples 3040, speed 662.86 words/sec, time elapsed 1371.40 sec\n",
      "epoch 1, iter 2000, avg. loss 189.79, avg. ppl 32.01 cum. examples 3200, speed 683.38 words/sec, time elapsed 1384.22 sec\n",
      "epoch 1, iter 2000, cum. loss 195.17, cum. ppl 35.53 cum. examples 3200\n",
      "begin validation ...\n",
      "validation: iter 2000, dev. ppl 41.589036\n",
      "save currently the best model to [model.bin]\n",
      "save model parameters to [model.bin]\n",
      "epoch 1, iter 2020, avg. loss 185.17, avg. ppl 34.37 cum. examples 160, speed 281.03 words/sec, time elapsed 1414.02 sec\n",
      "epoch 1, iter 2040, avg. loss 187.14, avg. ppl 32.51 cum. examples 320, speed 663.96 words/sec, time elapsed 1426.98 sec\n",
      "epoch 1, iter 2060, avg. loss 191.07, avg. ppl 35.67 cum. examples 480, speed 665.16 words/sec, time elapsed 1439.84 sec\n",
      "epoch 1, iter 2080, avg. loss 185.78, avg. ppl 30.46 cum. examples 640, speed 676.00 words/sec, time elapsed 1452.71 sec\n",
      "epoch 1, iter 2100, avg. loss 201.69, avg. ppl 40.36 cum. examples 800, speed 634.77 words/sec, time elapsed 1466.46 sec\n",
      "epoch 1, iter 2120, avg. loss 195.18, avg. ppl 42.02 cum. examples 960, speed 638.73 words/sec, time elapsed 1479.54 sec\n",
      "epoch 1, iter 2140, avg. loss 191.61, avg. ppl 33.21 cum. examples 1120, speed 690.56 words/sec, time elapsed 1492.21 sec\n",
      "epoch 1, iter 2160, avg. loss 195.72, avg. ppl 33.17 cum. examples 1280, speed 688.33 words/sec, time elapsed 1505.20 sec\n",
      "epoch 1, iter 2180, avg. loss 192.18, avg. ppl 34.25 cum. examples 1440, speed 650.21 words/sec, time elapsed 1518.58 sec\n",
      "epoch 1, iter 2200, avg. loss 190.92, avg. ppl 34.29 cum. examples 1600, speed 640.81 words/sec, time elapsed 1532.07 sec\n",
      "epoch 1, iter 2220, avg. loss 191.18, avg. ppl 38.43 cum. examples 1760, speed 626.58 words/sec, time elapsed 1545.45 sec\n",
      "epoch 1, iter 2240, avg. loss 194.91, avg. ppl 31.85 cum. examples 1920, speed 661.72 words/sec, time elapsed 1559.07 sec\n",
      "epoch 1, iter 2260, avg. loss 186.58, avg. ppl 33.51 cum. examples 2080, speed 656.50 words/sec, time elapsed 1572.02 sec\n",
      "epoch 1, iter 2280, avg. loss 185.60, avg. ppl 33.33 cum. examples 2240, speed 652.71 words/sec, time elapsed 1584.99 sec\n",
      "epoch 1, iter 2300, avg. loss 185.65, avg. ppl 28.97 cum. examples 2400, speed 664.66 words/sec, time elapsed 1598.27 sec\n",
      "epoch 1, iter 2320, avg. loss 195.12, avg. ppl 31.33 cum. examples 2560, speed 684.77 words/sec, time elapsed 1611.50 sec\n",
      "epoch 1, iter 2340, avg. loss 182.47, avg. ppl 36.77 cum. examples 2720, speed 625.88 words/sec, time elapsed 1624.44 sec\n",
      "epoch 1, iter 2360, avg. loss 191.85, avg. ppl 35.14 cum. examples 2880, speed 666.91 words/sec, time elapsed 1637.37 sec\n",
      "epoch 1, iter 2380, avg. loss 188.20, avg. ppl 38.35 cum. examples 3040, speed 639.99 words/sec, time elapsed 1650.28 sec\n",
      "epoch 1, iter 2400, avg. loss 195.84, avg. ppl 28.73 cum. examples 3200, speed 691.55 words/sec, time elapsed 1663.77 sec\n",
      "epoch 1, iter 2400, cum. loss 190.69, cum. ppl 34.09 cum. examples 3200\n",
      "begin validation ...\n",
      "validation: iter 2400, dev. ppl 39.267354\n",
      "save currently the best model to [model.bin]\n",
      "save model parameters to [model.bin]\n",
      "epoch 1, iter 2420, avg. loss 191.78, avg. ppl 38.31 cum. examples 160, speed 286.89 words/sec, time elapsed 1693.11 sec\n",
      "epoch 1, iter 2440, avg. loss 189.48, avg. ppl 33.24 cum. examples 320, speed 668.88 words/sec, time elapsed 1706.04 sec\n",
      "epoch 1, iter 2460, avg. loss 192.78, avg. ppl 32.92 cum. examples 480, speed 657.25 words/sec, time elapsed 1719.48 sec\n",
      "epoch 1, iter 2480, avg. loss 189.88, avg. ppl 34.41 cum. examples 640, speed 633.66 words/sec, time elapsed 1733.03 sec\n",
      "epoch 1, iter 2500, avg. loss 191.45, avg. ppl 33.10 cum. examples 800, speed 655.39 words/sec, time elapsed 1746.38 sec\n",
      "epoch 1, iter 2520, avg. loss 190.45, avg. ppl 30.72 cum. examples 960, speed 680.45 words/sec, time elapsed 1759.46 sec\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!sh run_en2ko.sh train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char_size : 85\n",
      "uniformly initialize parameters [-0.100000, +0.100000]\n",
      "use device: cpu\n",
      "begin Maximum Likelihood training\n",
      "slang : en, tlang : ko\n",
      "/home/jupyter/Project/nmt_bi_mono_mapping_combined_0717/nmt_model.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  XO = torch.tensor(pad_sequence(XO)).to(self.device) #,device = self.device) #<=[:-1]\n",
      "epoch 1, iter 20, avg. loss 419.16, avg. ppl 1918.51 cum. examples 80, speed 204.87 words/sec, time elapsed 21.65 sec\n",
      "epoch 1, iter 40, avg. loss 392.43, avg. ppl 1277.92 cum. examples 160, speed 199.70 words/sec, time elapsed 43.63 sec\n",
      "epoch 1, iter 60, avg. loss 354.58, avg. ppl 1120.38 cum. examples 240, speed 196.24 words/sec, time elapsed 64.22 sec\n",
      "epoch 1, iter 80, avg. loss 334.43, avg. ppl 766.66 cum. examples 320, speed 188.59 words/sec, time elapsed 85.58 sec\n",
      "epoch 1, iter 100, avg. loss 323.00, avg. ppl 607.17 cum. examples 400, speed 185.51 words/sec, time elapsed 107.31 sec\n",
      "epoch 1, iter 100, cum. loss 364.72, cum. ppl 1066.32 cum. examples 400\n",
      "begin validation ...\n",
      "Traceback (most recent call last):\n",
      "  File \"run.py\", line 694, in <module>\n",
      "    main()\n",
      "  File \"run.py\", line 684, in main\n",
      "    train(args)\n",
      "  File \"run.py\", line 468, in train\n",
      "    dev_ppl = evaluate_ppl(model, dev_data, slang, tlang, batch_size=32)   \n",
      "  File \"run.py\", line 93, in evaluate_ppl\n",
      "    loss = -model(src_sents, tgt_sents, slang=slang, tlang=tlang).sum()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/jupyter/Project/nmt_bi_mono_mapping_combined_0717/nmt_model.py\", line 237, in forward\n",
      "    P = F.log_softmax(self.target_vocab_projection(combined_outputs), dim=-1)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/linear.py\", line 67, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\", line 1354, in linear\n",
      "    output = input.matmul(weight.t())\n",
      "RuntimeError: $ Torch: not enough memory: you tried to allocate 0GB. Buy new RAM! at /pytorch/aten/src/TH/THGeneral.cpp:201\n"
     ]
    }
   ],
   "source": [
    "!sh run_en2ko.sh train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.tensor([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0400, 0.8495, 3.1826])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.040024757385254, 0.8494502305984497, 3.1825804710388184]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " [s.item() for s in x[:,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7376,  1.3918,  0.6330,  1.2007],\n",
       "        [ 1.3273,  1.5605, -0.5510, -0.0176],\n",
       "        [ 0.5728,  0.7638,  0.2747, -1.2880]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[s.item() for s in ss[0]] for ss in torch.split(x,1,0)]).size()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[s[0].item() for s in ss] for ss in torch.split(x,1,-1)]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
